{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><img src=\"../../images/ATLASOD.gif\" style=\"width:50%\"></CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to rediscover the Higgs boson yourself!\n",
    "This notebook uses ATLAS Open Data http://opendata.atlas.cern to show you the steps to rediscover the Higgs boson yourself!\n",
    "\n",
    "ATLAS Open Data provides open access to proton-proton collision data at the LHC for educational purposes. ATLAS Open Data resources are ideal for high-school, undergraduate and postgraduate students.\n",
    "\n",
    "Notebooks are web applications that allow you to create and share documents that can contain for example:\n",
    "1. live code\n",
    "2. visualisations\n",
    "3. narrative text\n",
    "\n",
    "The idea is that cuts increase the ratio of signal ($H \\rightarrow ZZ \\rightarrow \\ell\\ell\\ell\\ell$) to background ($Z, t\\bar{t}, ZZ \\rightarrow \\ell\\ell\\ell\\ell$)\n",
    "\n",
    "First, the amount of $Z$ and $t\\bar{t}$ background is reduced, since these are quite different to the signal.\n",
    "\n",
    "Then, the amount of $ZZ \\rightarrow \\ell\\ell\\ell\\ell$ is reduced, whilst keeping as much $H \\rightarrow ZZ \\rightarrow \\ell\\ell\\ell\\ell$ signal as possible.\n",
    "\n",
    "The datasets used in this notebook have already been filtered to include at least 4 leptons per event, so that processing is quicker.\n",
    "\n",
    "This analysis loosely follows the [discovery of the Higgs boson by ATLAS](https://www.sciencedirect.com/science/article/pii/S037026931200857X) (mostly Section 4 and 4.1)\n",
    "\n",
    "By the end of this notebook you will be able to:\n",
    "1. rediscover the Higgs boson yourself!\n",
    "2. know some general principles of a particle physics analysis\n",
    "\n",
    "Feynman diagram pictures are borrowed from our friends at https://www.particlezoo.net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><img src=\"images/feynman_diagrams/HZZ_feynman.png\" style=\"width:40%\"></CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='contents'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents: \n",
    "\n",
    "[Running a Jupyter notebook](#running) <br />\n",
    "[First time setup on your computer (no need on mybinder)](#setup_computer) <br />\n",
    "[To setup everytime](#setup_everytime) <br />\n",
    "[Lumi, fraction, file path](#fraction) <br />\n",
    "[Samples](#samples) <br />\n",
    "[Changing a cut](#changing_cut) <br />\n",
    "[Applying a cut](#applying_cut) <br />\n",
    "[Plotting](#plotting) <br />\n",
    "[What can you do to explore this analysis?](#going_further) <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='running'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a Jupyter notebook\n",
    "\n",
    "To run the whole Jupyter notebook, in the top menu click Cell -> Run All.\n",
    "\n",
    "To propagate a change you've made to a piece of code, click Cell -> Run All Below.\n",
    "\n",
    "You can also run a single code cell, by clicking Cell -> Run Cells, or using the keyboard shortcut Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup_computer'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First time setup on your computer (no need on mybinder)\n",
    "This first cell only needs to be run the first time you open this notebook on your computer. \n",
    "\n",
    "If you close Jupyter and re-open on the same computer, you won't need to run this first cell again.\n",
    "\n",
    "If you open on mybinder, you don't need to run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/user/.local/lib/python3.8/site-packages (23.3.1)\n",
      "\u001b[33mDEPRECATION: distro-info 0.23ubuntu1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.36ubuntu1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: uproot in /home/user/.local/lib/python3.8/site-packages (5.1.2)\n",
      "Requirement already satisfied: awkward in /home/user/.local/lib/python3.8/site-packages (2.5.0)\n",
      "Requirement already satisfied: vector in /home/user/.local/lib/python3.8/site-packages (1.1.1.post1)\n",
      "Requirement already satisfied: numpy in /home/user/.local/lib/python3.8/site-packages (1.24.4)\n",
      "Requirement already satisfied: matplotlib in /home/user/.local/lib/python3.8/site-packages (3.7.4)\n",
      "Requirement already satisfied: packaging in /home/user/.local/lib/python3.8/site-packages (from uproot) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/user/.local/lib/python3.8/site-packages (from uproot) (4.8.0)\n",
      "Requirement already satisfied: awkward-cpp==26 in /home/user/.local/lib/python3.8/site-packages (from awkward) (26)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /home/user/.local/lib/python3.8/site-packages (from awkward) (6.0.0)\n",
      "Requirement already satisfied: importlib_resources in /home/user/.local/lib/python3.8/site-packages (from awkward-cpp==26->awkward) (6.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/user/.local/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/user/.local/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/user/.local/lib/python3.8/site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/user/.local/lib/python3.8/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib) (7.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/user/.local/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/user/.local/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/user/.local/lib/python3.8/site-packages (from importlib-metadata>=4.13.0->awkward) (3.14.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.14.0)\n",
      "\u001b[33mDEPRECATION: distro-info 0.23ubuntu1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.36ubuntu1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# update the pip package installer\n",
    "!{sys.executable} -m pip install --upgrade --user pip\n",
    "# install required packages\n",
    "!{sys.executable} -m pip install --upgrade --user uproot awkward vector numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup_everytime'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To setup everytime\n",
    "Cell -> Run All Below\n",
    "\n",
    "to be done every time you re-open this notebook\n",
    "\n",
    "We're going to be using a number of tools to help us:\n",
    "* uproot: lets us read .root files typically used in particle physics into data formats used in python\n",
    "* awkward: lets us store data as awkward arrays, a format that generalizes numpy to nested data with possibly variable length lists\n",
    "* vector: to allow vectorized 4-momentum calculations\n",
    "* numpy: provides numerical calculations such as histogramming\n",
    "* matplotlib: common tool for making plots, figures, images, visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot # for reading .root files\n",
    "import awkward as ak # to represent nested data in columnar format\n",
    "import vector # for 4-momentum calculations\n",
    "import time # to measure time to analyse\n",
    "import math # for mathematical functions such as square root\n",
    "import numpy as np # for numerical calculations such as histogramming\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "from matplotlib.ticker import AutoMinorLocator # for minor ticks\n",
    "from multiprocessing import Pool \n",
    "\n",
    "import infofile # local file containing cross-sections, sums of weights, dataset IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fraction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lumi, fraction, file path\n",
    "\n",
    "General definitions of fraction of data used, where to access the input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lumi = 0.5 # fb-1 # data_A only\n",
    "#lumi = 1.9 # fb-1 # data_B only\n",
    "#lumi = 2.9 # fb-1 # data_C only\n",
    "#lumi = 4.7 # fb-1 # data_D only\n",
    "lumi = 10 # fb-1 # data_A,data_B,data_C,data_D\n",
    "\n",
    "fraction = 1.0 # reduce this is if you want the code to run quicker\n",
    "                                                                                                                                  \n",
    "#tuple_path = \"Input/4lep/\" # local \n",
    "tuple_path = \"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/4lep/\" # web address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='samples'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples\n",
    "\n",
    "samples to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {\n",
    "\n",
    "    'data': {\n",
    "        'list' : ['data_A','data_B','data_C','data_D'],\n",
    "    },\n",
    "\n",
    "    # r'Background $Z,t\\bar{t}$' : { # Z + ttbar\n",
    "    #     'list' : ['Zee','Zmumu','ttbar_lep'],\n",
    "    #     'color' : \"#6b59d3\" # purple\n",
    "    # },\n",
    "\n",
    "    # r'Background $ZZ^*$' : { # ZZ\n",
    "    #     'list' : ['llll'],\n",
    "    #     'color' : \"#ff0000\" # red\n",
    "    # },\n",
    "\n",
    "    # r'Signal ($m_H$ = 125 GeV)' : { # H -> ZZ -> llll\n",
    "    #     'list' : ['ggH125_ZZ4lep','VBFH125_ZZ4lep','WH125_ZZ4lep','ZH125_ZZ4lep'],\n",
    "    #     'color' : \"#00cdff\" # light blue\n",
    "    # },\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Units, as stored in the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MeV = 0.001\n",
    "GeV = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to get data from files.\n",
    "\n",
    "The datasets used in this notebook have already been filtered to include at least 4 leptons per event, so that processing is quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data_from_files():\n",
    "\n",
    "\n",
    "    data = {} # define empty dictionary to hold awkward arrays\n",
    "    for s in samples: # loop over samples\n",
    "        print('Processing '+s+' samples') # print which sample\n",
    "        frames = [] # define empty list to hold data\n",
    "        for val in samples[s]['list']: # loop over each file\n",
    "            if s == 'data': prefix = \"Data/\" # Data prefix\n",
    "            else: # MC prefix\n",
    "                prefix = \"MC/mc_\"+str(infofile.infos[val][\"DSID\"])+\".\"\n",
    "            fileString = tuple_path+prefix+val+\".4lep.root\" # file name to open\n",
    "            temp = read_file(fileString,val) # call the function read_file defined below\n",
    "            frames.append(temp) # append array returned from read_file to list of awkward arrays\n",
    "        data[s] = ak.concatenate(frames) # dictionary entry is concatenated awkward arrays\n",
    "    \n",
    "    return data # return dictionary of awkward arrays\n",
    "\n",
    "# This function will be mapped to multiple processes\n",
    "# def process_file(args):\n",
    "#     val, s = args\n",
    "#     if s == 'data': \n",
    "#         prefix = \"Data/\" \n",
    "#     else: \n",
    "#         prefix = \"MC/mc_\"+str(infofile.infos[val][\"DSID\"])+\".\"\n",
    "#     fileString = tuple_path+prefix+val+\".4lep.root\" \n",
    "#     return read_file(fileString,val)\n",
    "\n",
    "# def get_data_from_files():\n",
    "#     data = {} \n",
    "#     for s in samples: \n",
    "#         print('Processing '+s+' samples') \n",
    "#         with Pool() as p:\n",
    "#             file_args = [(val, s) for val in samples[s]['list']]\n",
    "#             frames = p.map(process_file, file_args)\n",
    "#         data[s] = ak.concatenate(frames) \n",
    "#     return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define function to calculate weight of MC event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_weight(xsec_weight, events):\n",
    "    return (\n",
    "        xsec_weight\n",
    "        * events.mcWeight\n",
    "        * events.scaleFactor_PILEUP\n",
    "        * events.scaleFactor_ELE\n",
    "        * events.scaleFactor_MUON \n",
    "        * events.scaleFactor_LepTRIGGER\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define function to get cross-section weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xsec_weight(sample):\n",
    "    info = infofile.infos[sample] # open infofile\n",
    "    xsec_weight = (lumi*1000*info[\"xsec\"])/(info[\"sumw\"]*info[\"red_eff\"]) #*1000 to go from fb-1 to pb-1\n",
    "    return xsec_weight # return cross-section weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define function to calculate 4-lepton invariant mass.\n",
    "\n",
    "Note: `lep_(pt|eta|phi|E)` are variable length lists of lepton momentum components for each event, represented by awkward arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mllll(lep_pt, lep_eta, lep_phi, lep_E):\n",
    "    # construct awkward 4-vector array\n",
    "    p4 = vector.zip({\"pt\": lep_pt, \"eta\": lep_eta, \"phi\": lep_phi, \"E\": lep_E})\n",
    "    # calculate invariant mass of first 4 leptons\n",
    "    # [:, i] selects the i-th lepton in each event\n",
    "    # .M calculates the invariant mass\n",
    "    return (p4[:, 0] + p4[:, 1] + p4[:, 2] + p4[:, 3]).M * MeV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='changing_cut'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing a cut\n",
    "\n",
    "If you change a cut: Cell -> Run All Below\n",
    "\n",
    "If you change a cut here, you also need to make sure the cut is applied in the \"[Applying a cut](#applying_cut)\" cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper: \"selecting two pairs of isolated leptons, each of which is comprised of two leptons with the same flavour and opposite charge\"\n",
    "def cut_lep_charge(lep_charge):\n",
    "# throw away when sum of lepton charges is not equal to 0\n",
    "# first lepton in each event is [:, 0], 2nd lepton is [:, 1] etc\n",
    "    return lep_charge[:, 0] + lep_charge[:, 1] + lep_charge[:, 2] + lep_charge[:, 3] != 0\n",
    "\n",
    "# cut on lepton type\n",
    "# paper: \"selecting two pairs of isolated leptons, each of which is comprised of two leptons with the same flavour and opposite charge\"\n",
    "def cut_lep_type(lep_type):\n",
    "# for an electron lep_type is 11\n",
    "# for a muon lep_type is 13\n",
    "# throw away when none of eeee, mumumumu, eemumuep_type[:, 2] + lep_type[:, 3]\n",
    "    sum_lep_type = lep_type[:, 0] + lep_type[:, 1] + lep_type[:, 2] + lep_type[:, 3]\n",
    "    return (sum_lep_type != 44) & (sum_lep_type != 48) & (sum_lep_type != 52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='applying_cut'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a cut\n",
    "If you add a cut: Cell -> Run All Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(args):\n",
    "    data, sample = args\n",
    "    if 'data' not in sample: xsec_weight = get_xsec_weight(sample) # get cross-section weight\n",
    "    # Process the chunk and return the result\n",
    "    if 'data' not in sample: # only do this for Monte Carlo simulation files\n",
    "        # multiply all Monte Carlo weights and scale factors together to give total weight\n",
    "        data['totalWeight'] = calc_weight(xsec_weight, data)\n",
    "\n",
    "    # cut on lepton charge using the function cut_lep_charge defined above\n",
    "    data = data[~cut_lep_charge(data.lep_charge)]\n",
    "\n",
    "    # cut on lepton type using the function cut_lep_type defined above\n",
    "    data = data[~cut_lep_type(data.lep_type)]\n",
    "\n",
    "    # calculation of 4-lepton invariant mass using the function calc_mllll defined above\n",
    "    data['mllll'] = calc_mllll(data.lep_pt, data.lep_eta, data.lep_phi, data.lep_E)\n",
    "\n",
    "    # array contents can be printed at any stage like this\n",
    "    #print(data)\n",
    "\n",
    "    # array column can be printed at any stage like this\n",
    "    #print(data['lep_pt'])\n",
    "\n",
    "    # multiple array columns can be printed at any stage like this\n",
    "    #print(data[['lep_pt','lep_eta']])\n",
    "    #nOut = len(data) # number of events passing cuts in this batch\n",
    "    return data\n",
    "\n",
    "def read_file(path,sample):\n",
    "    start = time.time() # start the clock\n",
    "    print(\"\\tProcessing: \"+sample) # print which sample is being processed\n",
    "    data_all = [] # define empty list to hold all data for this sample\n",
    "    \n",
    "    # open the tree called mini using a context manager (will automatically close files/resources)\n",
    "    with uproot.open(path + \":mini\") as tree:\n",
    "        numevents = tree.num_entries # number of event\n",
    "        tasks = []\n",
    "        for data in tree.iterate(['lep_pt','lep_eta','lep_phi',\n",
    "                                  'lep_E','lep_charge','lep_type', \n",
    "                                  # add more variables here if you make cuts on them \n",
    "                                  'mcWeight','scaleFactor_PILEUP',\n",
    "                                  'scaleFactor_ELE','scaleFactor_MUON',\n",
    "                                  'scaleFactor_LepTRIGGER'], # variables to calculate Monte Carlo weight\n",
    "                                 library=\"ak\", # choose output type as awkward array\n",
    "                                 entry_stop=numevents*fraction): # process up to numevents*fraction\n",
    "            tasks.append((data, sample))\n",
    "\n",
    "            nIn = len(data) # number of events in this batch\n",
    "\n",
    "        with Pool() as p:\n",
    "            data_all = p.map(process_chunk,tasks)\n",
    "\n",
    "    return ak.concatenate(data_all) # return array containing events passing all cuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the processing happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data samples\n",
      "\tProcessing: data_A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tProcessing: data_B\n",
      "\tProcessing: data_C\n",
      "\tProcessing: data_D\n",
      "Time taken: 23.4s\n"
     ]
    }
   ],
   "source": [
    "start = time.time() # time at start of whole processing\n",
    "data = get_data_from_files() # process all files\n",
    "elapsed = time.time() - start # time after whole processing\n",
    "print(\"Time taken: \"+str(round(elapsed,1))+\"s\") # print total time taken to process every file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plotting'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "If you only want to make a change in plotting: Cell -> Run All Below\n",
    "\n",
    "Define function to plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data):\n",
    "\n",
    "    xmin = 80 * GeV\n",
    "    xmax = 250 * GeV\n",
    "    step_size = 5 * GeV\n",
    "\n",
    "    bin_edges = np.arange(start=xmin, # The interval includes this value\n",
    "                     stop=xmax+step_size, # The interval doesn't include this value\n",
    "                     step=step_size ) # Spacing between values\n",
    "    bin_centres = np.arange(start=xmin+step_size/2, # The interval includes this value\n",
    "                            stop=xmax+step_size/2, # The interval doesn't include this value\n",
    "                            step=step_size ) # Spacing between values\n",
    "\n",
    "    data_x,_ = np.histogram(ak.to_numpy(data['data']['mllll']), \n",
    "                            bins=bin_edges ) # histogram the data\n",
    "    data_x_errors = np.sqrt( data_x ) # statistical error on the data\n",
    "\n",
    "    signal_x = ak.to_numpy(data[r'Signal ($m_H$ = 125 GeV)']['mllll']) # histogram the signal\n",
    "    signal_weights = ak.to_numpy(data[r'Signal ($m_H$ = 125 GeV)'].totalWeight) # get the weights of the signal events\n",
    "    signal_color = samples[r'Signal ($m_H$ = 125 GeV)']['color'] # get the colour for the signal bar\n",
    "\n",
    "    mc_x = [] # define list to hold the Monte Carlo histogram entries\n",
    "    mc_weights = [] # define list to hold the Monte Carlo weights\n",
    "    mc_colors = [] # define list to hold the colors of the Monte Carlo bars\n",
    "    mc_labels = [] # define list to hold the legend labels of the Monte Carlo bars\n",
    "\n",
    "    for s in samples: # loop over samples\n",
    "        if s not in ['data', r'Signal ($m_H$ = 125 GeV)']: # if not data nor signal\n",
    "            mc_x.append( ak.to_numpy(data[s]['mllll']) ) # append to the list of Monte Carlo histogram entries\n",
    "            mc_weights.append( ak.to_numpy(data[s].totalWeight) ) # append to the list of Monte Carlo weights\n",
    "            mc_colors.append( samples[s]['color'] ) # append to the list of Monte Carlo bar colors\n",
    "            mc_labels.append( s ) # append to the list of Monte Carlo legend labels\n",
    "    \n",
    "\n",
    "\n",
    "    # *************\n",
    "    # Main plot \n",
    "    # *************\n",
    "    main_axes = plt.gca() # get current axes\n",
    "    \n",
    "    # plot the data points\n",
    "    main_axes.errorbar(x=bin_centres, y=data_x, yerr=data_x_errors,\n",
    "                       fmt='ko', # 'k' means black and 'o' is for circles \n",
    "                       label='Data') \n",
    "    \n",
    "    # plot the Monte Carlo bars\n",
    "    mc_heights = main_axes.hist(mc_x, bins=bin_edges, \n",
    "                                weights=mc_weights, stacked=True, \n",
    "                                color=mc_colors, label=mc_labels )\n",
    "    \n",
    "    mc_x_tot = mc_heights[0][-1] # stacked background MC y-axis value\n",
    "    \n",
    "    # calculate MC statistical uncertainty: sqrt(sum w^2)\n",
    "    mc_x_err = np.sqrt(np.histogram(np.hstack(mc_x), bins=bin_edges, weights=np.hstack(mc_weights)**2)[0])\n",
    "    \n",
    "    # plot the signal bar\n",
    "    main_axes.hist(signal_x, bins=bin_edges, bottom=mc_x_tot, \n",
    "                   weights=signal_weights, color=signal_color,\n",
    "                   label=r'Signal ($m_H$ = 125 GeV)')\n",
    "    \n",
    "    # plot the statistical uncertainty\n",
    "    main_axes.bar(bin_centres, # x\n",
    "                  2*mc_x_err, # heights\n",
    "                  alpha=0.5, # half transparency\n",
    "                  bottom=mc_x_tot-mc_x_err, color='none', \n",
    "                  hatch=\"////\", width=step_size, label='Stat. Unc.' )\n",
    "\n",
    "    # set the x-limit of the main axes\n",
    "    main_axes.set_xlim( left=xmin, right=xmax ) \n",
    "    \n",
    "    # separation of x axis minor ticks\n",
    "    main_axes.xaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "    \n",
    "    # set the axis tick parameters for the main axes\n",
    "    main_axes.tick_params(which='both', # ticks on both x and y axes\n",
    "                          direction='in', # Put ticks inside and outside the axes\n",
    "                          top=True, # draw ticks on the top axis\n",
    "                          right=True ) # draw ticks on right axis\n",
    "    \n",
    "    # x-axis label\n",
    "    main_axes.set_xlabel(r'4-lepton invariant mass $\\mathrm{m_{4l}}$ [GeV]',\n",
    "                        fontsize=13, x=1, horizontalalignment='right' )\n",
    "    \n",
    "    # write y-axis label for main axes\n",
    "    main_axes.set_ylabel('Events / '+str(step_size)+' GeV',\n",
    "                         y=1, horizontalalignment='right') \n",
    "    \n",
    "    # set y-axis limits for main axes\n",
    "    main_axes.set_ylim( bottom=0, top=np.amax(data_x)*1.6 )\n",
    "    \n",
    "    # add minor ticks on y-axis for main axes\n",
    "    main_axes.yaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "\n",
    "    # Add text 'ATLAS Open Data' on plot\n",
    "    plt.text(0.05, # x\n",
    "             0.93, # y\n",
    "             'ATLAS Open Data', # text\n",
    "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "             fontsize=13 ) \n",
    "    \n",
    "    # Add text 'for education' on plot\n",
    "    plt.text(0.05, # x\n",
    "             0.88, # y\n",
    "             'for education', # text\n",
    "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "             style='italic',\n",
    "             fontsize=8 ) \n",
    "    \n",
    "    # Add energy and luminosity\n",
    "    lumi_used = str(lumi*fraction) # luminosity to write on the plot\n",
    "    plt.text(0.05, # x\n",
    "             0.82, # y\n",
    "             '$\\sqrt{s}$=13 TeV,$\\int$L dt = '+lumi_used+' fb$^{-1}$', # text\n",
    "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes\n",
    "    \n",
    "    # Add a label for the analysis carried out\n",
    "    plt.text(0.05, # x\n",
    "             0.76, # y\n",
    "             r'$H \\rightarrow ZZ^* \\rightarrow 4\\ell$', # text \n",
    "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes\n",
    "\n",
    "    # draw the legend\n",
    "    main_axes.legend( frameon=False ) # no box around the legend\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function to plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Signal ($m_H$ = 125 GeV)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/user/Documents/Fourth_year/SciComp/miniProject2/miniproj/HZZAnalysis.ipynb Cell 51\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/user/Documents/Fourth_year/SciComp/miniProject2/miniproj/HZZAnalysis.ipynb#Y101sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plot_data(data)\n",
      "\u001b[1;32m/home/user/Documents/Fourth_year/SciComp/miniProject2/miniproj/HZZAnalysis.ipynb Cell 51\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Documents/Fourth_year/SciComp/miniProject2/miniproj/HZZAnalysis.ipynb#Y101sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m data_x,_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mhistogram(ak\u001b[39m.\u001b[39mto_numpy(data[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmllll\u001b[39m\u001b[39m'\u001b[39m]), \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Documents/Fourth_year/SciComp/miniProject2/miniproj/HZZAnalysis.ipynb#Y101sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                         bins\u001b[39m=\u001b[39mbin_edges ) \u001b[39m# histogram the data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Documents/Fourth_year/SciComp/miniProject2/miniproj/HZZAnalysis.ipynb#Y101sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m data_x_errors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt( data_x ) \u001b[39m# statistical error on the data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/user/Documents/Fourth_year/SciComp/miniProject2/miniproj/HZZAnalysis.ipynb#Y101sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m signal_x \u001b[39m=\u001b[39m ak\u001b[39m.\u001b[39mto_numpy(data[\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mSignal ($m_H$ = 125 GeV)\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mmllll\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m# histogram the signal\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Documents/Fourth_year/SciComp/miniProject2/miniproj/HZZAnalysis.ipynb#Y101sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m signal_weights \u001b[39m=\u001b[39m ak\u001b[39m.\u001b[39mto_numpy(data[\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSignal ($m_H$ = 125 GeV)\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtotalWeight) \u001b[39m# get the weights of the signal events\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/user/Documents/Fourth_year/SciComp/miniProject2/miniproj/HZZAnalysis.ipynb#Y101sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m signal_color \u001b[39m=\u001b[39m samples[\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSignal ($m_H$ = 125 GeV)\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcolor\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m# get the colour for the signal bar\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Signal ($m_H$ = 125 GeV)'"
     ]
    }
   ],
   "source": [
    "plot_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='going_further'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can you do to explore this analysis?\n",
    "\n",
    "* Increase the fraction of data used in '[Lumi, fraction, file path](#fraction)'\n",
    "* Check how many events are being thrown away by each cut in '[Applying a cut](#applying_cut)'\n",
    "* Add more cuts from the [Higgs discovery paper](https://www.sciencedirect.com/science/article/pii/S037026931200857X#se0040) in '[Changing a cut](#changing_cut)' and '[Applying a cut](#applying_cut)'\n",
    "* Add a plot to show the ratio between Data and MC other than Higgs\n",
    "* Add a plot to show the invariant mass distribution of the sub-leading lepton pair, like [Figure 1 of the Higgs discovery paper](https://www.sciencedirect.com/science/article/pii/S037026931200857X#fg0010)\n",
    "* Get the estimated numbers of events, like [Table 3 of the Higgs discovery paper](https://www.sciencedirect.com/science/article/pii/S037026931200857X#tl0030)\n",
    "* Add a plot of m12 against m34, like [Figure 3 of the Higgs discovery paper](https://www.sciencedirect.com/science/article/pii/S037026931200857X#fg0030)\n",
    "* Your idea!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
